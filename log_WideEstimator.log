
=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH
{'train_logloss': 0.3633618300663759, 'train_auc': 0.8769603928235493, 'train_accuracy': 0.8306870182119713, 'test_logloss': 0.3516277956106794, 'test_auc': 0.8837503327234014, 'test_accuracy': 0.8366193722744303}

=============== 2-th EPOCH
{'train_logloss': 0.3533397877514203, 'train_auc': 0.8843938064748857, 'train_accuracy': 0.8349866404594454, 'test_logloss': 0.3503972350064218, 'test_auc': 0.8846351417386008, 'test_accuracy': 0.8382777470671334}

=============== 3-th EPOCH

=============== 1-th EPOCH
{'train_logloss': 0.3631359459062621, 'train_auc': 0.8771490947302557, 'train_accuracy': 0.8320690396486594, 'test_logloss': 0.35159692756487726, 'test_auc': 0.8837203902309692, 'test_accuracy': 0.8368650574289048}

=============== 2-th EPOCH
{'train_logloss': 0.3532788181108913, 'train_auc': 0.8844105428316595, 'train_accuracy': 0.835293756334265, 'test_logloss': 0.35022524172017117, 'test_auc': 0.8846812264127075, 'test_accuracy': 0.8382777470671334}

=============== 3-th EPOCH
{'train_logloss': 0.3520450312586222, 'train_auc': 0.8853531133957304, 'train_accuracy': 0.8361229691962777, 'test_logloss': 0.34945174342814506, 'test_auc': 0.8851811113055701, 'test_accuracy': 0.8379092193354216}

=============== 4-th EPOCH
{'train_logloss': 0.3515298045488241, 'train_auc': 0.8857049741442893, 'train_accuracy': 0.8362151039587237, 'test_logloss': 0.3492968597793601, 'test_auc': 0.8853709283071766, 'test_accuracy': 0.8387076960874639}

=============== 5-th EPOCH
{'train_logloss': 0.35112986797398993, 'train_auc': 0.8860245229931952, 'train_accuracy': 0.8363072387211695, 'test_logloss': 0.3490971659442354, 'test_auc': 0.8855715346426483, 'test_accuracy': 0.838523432221608}

=============== 6-th EPOCH
{'train_logloss': 0.3508462107119663, 'train_auc': 0.8862188587166702, 'train_accuracy': 0.8371364515831823, 'test_logloss': 0.3491278190845737, 'test_auc': 0.8857385393123807, 'test_accuracy': 0.8375406916037098}

=============== 7-th EPOCH
{'train_logloss': 0.3507731986283571, 'train_auc': 0.8863299047534142, 'train_accuracy': 0.8370443168207364, 'test_logloss': 0.3489655898136955, 'test_auc': 0.8856237876374725, 'test_accuracy': 0.8377863767581843}

=============== 8-th EPOCH
{'train_logloss': 0.3505393282356555, 'train_auc': 0.8864989760073698, 'train_accuracy': 0.837351432695556, 'test_logloss': 0.34883941992099904, 'test_auc': 0.8858668403833058, 'test_accuracy': 0.8377863767581843}

=============== 9-th EPOCH
{'train_logloss': 0.3505328130659855, 'train_auc': 0.8864759093454908, 'train_accuracy': 0.8374435674580019, 'test_logloss': 0.3487778771799946, 'test_auc': 0.8858616966311141, 'test_accuracy': 0.8377249554695657}

=============== 10-th EPOCH
{'train_logloss': 0.35044100169711057, 'train_auc': 0.8865600606140902, 'train_accuracy': 0.8367372009459169, 'test_logloss': 0.3488430107588277, 'test_auc': 0.8859881785701665, 'test_accuracy': 0.8374792703150912}

************** TIME COST **************
34.04 seconds for 10 epoches
14348.91 examples per second

************** LEARNING CURVE **************
   test_accuracy  test_auc      ...        train_auc  train_logloss
0       0.836865  0.883720      ...         0.877149       0.363136
1       0.838278  0.884681      ...         0.884411       0.353279
2       0.837909  0.885181      ...         0.885353       0.352045
3       0.838708  0.885371      ...         0.885705       0.351530
4       0.838523  0.885572      ...         0.886025       0.351130
5       0.837541  0.885739      ...         0.886219       0.350846
6       0.837786  0.885624      ...         0.886330       0.350773
7       0.837786  0.885867      ...         0.886499       0.350539
8       0.837725  0.885862      ...         0.886476       0.350533
9       0.837479  0.885988      ...         0.886560       0.350441

[10 rows x 6 columns]

=============== 1-th EPOCH

=============== 1-th EPOCH
{'train_logloss': 0.3631368674747548, 'train_auc': 0.8772836304810536, 'train_accuracy': 0.83160836583643, 'test_logloss': 0.35151817524900864, 'test_auc': 0.8837264749134397, 'test_accuracy': 0.8363122658313371}

=============== 2-th EPOCH
{'train_logloss': 0.3533633909586999, 'train_auc': 0.8843186889179728, 'train_accuracy': 0.8352630447467829, 'test_logloss': 0.35043303643132306, 'test_auc': 0.8845343994700681, 'test_accuracy': 0.8377863767581843}

=============== 3-th EPOCH
{'train_logloss': 0.3520966605139701, 'train_auc': 0.8852518904241211, 'train_accuracy': 0.8357237185590123, 'test_logloss': 0.3495251864733692, 'test_auc': 0.885234493416729, 'test_accuracy': 0.8376635341809471}

=============== 4-th EPOCH
{'train_logloss': 0.3515805171470739, 'train_auc': 0.8857128160870439, 'train_accuracy': 0.8357851417339762, 'test_logloss': 0.3492524726093258, 'test_auc': 0.8854087327948285, 'test_accuracy': 0.8377863767581843}

=============== 5-th EPOCH
{'train_logloss': 0.35123310337270863, 'train_auc': 0.8859619215896526, 'train_accuracy': 0.8365529314210252, 'test_logloss': 0.3490821118640801, 'test_auc': 0.8855600343836834, 'test_accuracy': 0.8375406916037098}

=============== 6-th EPOCH
{'train_logloss': 0.35093115362750127, 'train_auc': 0.8861509846384596, 'train_accuracy': 0.8363993734836154, 'test_logloss': 0.3491728903893874, 'test_auc': 0.8855154133788995, 'test_accuracy': 0.8385848535102266}

=============== 7-th EPOCH
{'train_logloss': 0.3507783494371962, 'train_auc': 0.8863072869395745, 'train_accuracy': 0.8366143545959891, 'test_logloss': 0.3490030170169698, 'test_auc': 0.8856691613864796, 'test_accuracy': 0.837847798046803}

=============== 8-th EPOCH
{'train_logloss': 0.3506301827424461, 'train_auc': 0.8864061418508388, 'train_accuracy': 0.8372285863456282, 'test_logloss': 0.34916482312737523, 'test_auc': 0.885805261723939, 'test_accuracy': 0.8374792703150912}

=============== 9-th EPOCH
{'train_logloss': 0.3505808087457813, 'train_auc': 0.8864370710921639, 'train_accuracy': 0.8371057399957004, 'test_logloss': 0.34884478413984754, 'test_auc': 0.8858550473904763, 'test_accuracy': 0.8379706406240403}

=============== 10-th EPOCH
{'train_logloss': 0.3505016214652131, 'train_auc': 0.8865035779895653, 'train_accuracy': 0.8372592979331102, 'test_logloss': 0.3487607601855197, 'test_auc': 0.8858825225546215, 'test_accuracy': 0.8380934832012775}

************** TIME COST **************
33.76 seconds for 10 epoches
14469.12 examples per second

************** LEARNING CURVE **************
   test_accuracy  test_auc      ...        train_auc  train_logloss
0       0.836312  0.883726      ...         0.877284       0.363137
1       0.837786  0.884534      ...         0.884319       0.353363
2       0.837664  0.885234      ...         0.885252       0.352097
3       0.837786  0.885409      ...         0.885713       0.351581
4       0.837541  0.885560      ...         0.885962       0.351233
5       0.838585  0.885515      ...         0.886151       0.350931
6       0.837848  0.885669      ...         0.886307       0.350778
7       0.837479  0.885805      ...         0.886406       0.350630
8       0.837971  0.885855      ...         0.886437       0.350581
9       0.838093  0.885883      ...         0.886504       0.350502

[10 rows x 6 columns]

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH

=============== 1-th EPOCH
{'train_logloss': 0.34613802200540333, 'train_auc': 0.889970273877787, 'train_accuracy': 0.8418046128804398, 'test_logloss': 0.33097168838870933, 'test_auc': 0.8984263568371444, 'test_accuracy': 0.8488422087095387}

=============== 2-th EPOCH
{'train_logloss': 0.3306065756576564, 'train_auc': 0.9001888979552753, 'train_accuracy': 0.8483461810140966, 'test_logloss': 0.32709373616119813, 'test_auc': 0.9005784421163738, 'test_accuracy': 0.8497635280388183}

=============== 3-th EPOCH
{'train_logloss': 0.32787398959322656, 'train_auc': 0.901795928710962, 'train_accuracy': 0.8493289518135192, 'test_logloss': 0.3254932310727268, 'test_auc': 0.9012916359034739, 'test_accuracy': 0.85148332412014}

=============== 4-th EPOCH
{'train_logloss': 0.3265638554757516, 'train_auc': 0.9026801903033139, 'train_accuracy': 0.8492982402260373, 'test_logloss': 0.32484406326965415, 'test_auc': 0.9016163195783963, 'test_accuracy': 0.8512376389656655}

=============== 5-th EPOCH
{'train_logloss': 0.3257204758976677, 'train_auc': 0.9032054302151705, 'train_accuracy': 0.8499431835631583, 'test_logloss': 0.32457211357663096, 'test_auc': 0.9018159849835892, 'test_accuracy': 0.85148332412014}

=============== 6-th EPOCH
{'train_logloss': 0.32517343580467056, 'train_auc': 0.9036249947892354, 'train_accuracy': 0.8499738951506404, 'test_logloss': 0.324002863891568, 'test_auc': 0.9021078615561189, 'test_accuracy': 0.851667587985996}

=============== 7-th EPOCH
{'train_logloss': 0.3246818028061214, 'train_auc': 0.9039060458902235, 'train_accuracy': 0.8497282024507847, 'test_logloss': 0.3237549348358986, 'test_auc': 0.9022698479310303, 'test_accuracy': 0.8517290092746146}

=============== 8-th EPOCH
{'train_logloss': 0.32431504396981187, 'train_auc': 0.9041317493847171, 'train_accuracy': 0.8498510488007125, 'test_logloss': 0.3235606214722436, 'test_auc': 0.902452994782437, 'test_accuracy': 0.8513604815429028}

=============== 9-th EPOCH
{'train_logloss': 0.3240523725451201, 'train_auc': 0.9043217514029854, 'train_accuracy': 0.8497589140382666, 'test_logloss': 0.32352636859391853, 'test_auc': 0.9024686142250676, 'test_accuracy': 0.8518518518518519}

=============== 10-th EPOCH
{'train_logloss': 0.3238233740622713, 'train_auc': 0.9044718833333539, 'train_accuracy': 0.8500046067381223, 'test_logloss': 0.3233529487617548, 'test_auc': 0.902521369049374, 'test_accuracy': 0.852158958294945}

************** TIME COST **************
54.52 seconds for 10 epoches
8958.43 examples per second

************** LEARNING CURVE **************
   test_accuracy  test_auc      ...        train_auc  train_logloss
0       0.848842  0.898426      ...         0.889970       0.346138
1       0.849764  0.900578      ...         0.900189       0.330607
2       0.851483  0.901292      ...         0.901796       0.327874
3       0.851238  0.901616      ...         0.902680       0.326564
4       0.851483  0.901816      ...         0.903205       0.325720
5       0.851668  0.902108      ...         0.903625       0.325173
6       0.851729  0.902270      ...         0.903906       0.324682
7       0.851360  0.902453      ...         0.904132       0.324315
8       0.851852  0.902469      ...         0.904322       0.324052
9       0.852159  0.902521      ...         0.904472       0.323823

[10 rows x 6 columns]
